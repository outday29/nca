{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660ddf07-0a8a-40e9-b51d-45320763b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# This will reload all modules every time you run a cell\n",
    "# You may refer to here https://switowski.com/blog/ipython-autoreload/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c41f71-839e-4874-bcbf-93971d5fd7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.rmtree(\"./lightning_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b66dcb-967d-4356-a24f-69dfdab5825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import einops\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from torch import optim\n",
    "\n",
    "from utils import VideoWriter, transform\n",
    "from display import NCAGrid\n",
    "from lightning_module import NCALightningModule\n",
    "from dataset import NCADataModule\n",
    "from model import Updater, Perceiver, NCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e83e810-c2e7-44fd-80dd-cd2d0f840665",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_CACHE = Path(\"./seed\") # For storing all seed caches\n",
    "SEED_CACHE_SIZE = 16 # Must be at least the batch_size, to avoid the drop_last, Might not be neccessary tho\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_STEP = 56\n",
    "\n",
    "SEED_CACHE.mkdir(exist_ok=True, parents=True)\n",
    "GRID_SIZE = (40, 40)\n",
    "CELL_FIRE_RATE = 0.5\n",
    "CLIP_VALUE = [-10, 10]\n",
    "ALIVE_THRESHOLD = 0.1\n",
    "USE_ALIVE_CHANNEL = True # If False, all cells are assume alive\n",
    "THUMBNAIL_SIZE = 32 # This controls the size of the target image, must be smaller than grid_size\n",
    "NUM_HIDDEN_CHANNELS = 18\n",
    "NUM_STATIC_CHANNELS = 0\n",
    "NUM_TARGET_CHANNELS = 3\n",
    "TOTAL_CHANNELS = NUM_HIDDEN_CHANNELS + NUM_STATIC_CHANNELS + NUM_TARGET_CHANNELS + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ad1a047",
   "metadata": {},
   "source": [
    "Defining our NCA dataset object, each NCA data in the dataset defines the state of the grid.\n",
    "\n",
    "Below are the explanation for each arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6221b2b8-f4c6-47c8-a0f8-05f4724327f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_dm = NCADataModule(\n",
    "    seed_cache_dir=SEED_CACHE, \n",
    "    grid_size=GRID_SIZE, \n",
    "    num_hidden_channels=NUM_HIDDEN_CHANNELS, \n",
    "    num_target_channels=NUM_TARGET_CHANNELS, \n",
    "    num_static_channels=NUM_STATIC_CHANNELS, \n",
    "    target_image_path=\"./pic/32/emoji_u0037_20e3.png\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    thumbnail_size=THUMBNAIL_SIZE,\n",
    "    clear_cache=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d396c7f1",
   "metadata": {},
   "source": [
    "Visualizing the target emoji that our NCA has to form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ea50fc-f94b-4c56-842c-bcbc55adcd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "to_pil_func = T.ToPILImage()\n",
    "img = to_pil_func(lit_dm.dataset.target_image_processed)\n",
    "img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5679750",
   "metadata": {},
   "source": [
    "Defining our NCA module. A NCA model will take in the current grid state provided by the DataModule object and output the next grid state.\n",
    "\n",
    "Every NCA module will have a `Perceiver` object defining how each individual cell in the grid receive the state information of its neighbouring cells, and an `Updater` object defining how to compute the change in cell state from the data received from `Perceiver`.\n",
    "\n",
    "\n",
    "Below are the explanation for each of the arguments:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e9181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NET_HIDDEN_CHANNELS = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d6e1770-97b3-4571-b35d-3e16ca9ebfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceiver(\n",
       "  (model): Conv2d(22, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceiver_net = Perceiver(in_channels=TOTAL_CHANNELS, out_channels=NET_HIDDEN_CHANNELS, groups=1)\n",
    "perceiver_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99abf91c-0dce-4079-957b-10c73f4ccc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Updater(\n",
       "  (out): Sequential(\n",
       "    (0): Conv2d(63, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updater_net = Updater(in_channels=NET_HIDDEN_CHANNELS, out_channels=TOTAL_CHANNELS)\n",
    "updater_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62cac612-48a3-4eaf-8270-5af1d9285348",
   "metadata": {},
   "outputs": [],
   "source": [
    "nca_2d = NCA(\n",
    "    num_hidden_channels = NUM_HIDDEN_CHANNELS,\n",
    "    num_target_channels = NUM_TARGET_CHANNELS,\n",
    "    num_static_channels = NUM_STATIC_CHANNELS,\n",
    "    use_alive_channel = USE_ALIVE_CHANNEL,\n",
    "    perceiver = perceiver_net,\n",
    "    updater= updater_net,\n",
    "    cell_fire_rate = CELL_FIRE_RATE,\n",
    "    clip_value = CLIP_VALUE,\n",
    "    alive_threshold = ALIVE_THRESHOLD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5586ac38-0697-4306-9809-0200579f6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = NCALightningModule(\n",
    "    model = nca_2d,\n",
    "    train_step = TRAIN_STEP,\n",
    "    seed_cache_dir = SEED_CACHE,\n",
    "    seed_cache_size = SEED_CACHE_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7d86bb1-4733-4471-9fa0-cd37d98fffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = NCALightningModule.load_from_checkpoint(\n",
    "    \"./tb_logs/lightning_logs/version_11/checkpoints/epoch=395-step=1585.ckpt\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cf893c4",
   "metadata": {},
   "source": [
    "After defining our grid and the NCA model, we are ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "888a21f9-040f-4195-98b7-02ee95f6c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_module.callback import get_num_generator, CacheBestSeed, CacheCorruptedSeed, VisualizeBestSeed, VisualizeRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2058833f-0b4e-4382-b1aa-ba278ae5b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_func = transform.create_corrupt_2d_circular(h=GRID_SIZE[0], w=GRID_SIZE[1], radius=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d7c6bc-eee5-440e-b1ed-3fd01be921ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\")\n",
    "\n",
    "num_gen = get_num_generator(SEED_CACHE_SIZE)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1000,\n",
    "    reload_dataloaders_every_n_epochs=1, # Since the seed cache is updated every epoch\n",
    "    callbacks=[\n",
    "        CacheBestSeed(cache_dir=SEED_CACHE, num_generator=num_gen),\n",
    "        VisualizeBestSeed(),\n",
    "        VisualizeRun(interval=30, simulate_step=TRAIN_STEP),\n",
    "        CacheCorruptedSeed(cache_dir=SEED_CACHE, num_generator=num_gen, loss_threshold=0.15, corrupt_func=corrupt_func)\n",
    "    ],\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87360431-071c-4e86-a1f3-f6f96e5db3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | NCA     | 22.1 K\n",
      "1 | loss  | MSELoss | 0     \n",
      "----------------------------------\n",
      "22.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "22.1 K    Total params\n",
      "0.089     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163:   0%|                                    | 0/4 [1:36:26<?, ?it/s, loss=0.0106, v_num=12]\n",
      "Epoch 242:   0%|                                     | 0/4 [00:00<?, ?it/s, loss=0.00706, v_num=12]"
     ]
    }
   ],
   "source": [
    "trainer.fit(lit_model, lit_dm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16542da5-8246-4faa-af4b-43715e29c284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d85f58-6fc2-46e2-a696-847042277d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbe209-78f1-42a3-b4e4-78435bc65a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
