{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b0aef7-8b53-4f55-b9d9-4400aae606e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473e95f9-a162-4001-acf8-a2a268daa89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lim Soon Yee\\.conda\\envs\\nca_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import einops\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eabcb3dc-7cda-4b99-a52c-1f0dfc85a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import VideoWriter, transform\n",
    "from display import NCAGrid\n",
    "from lightning_module import NCALightningModule\n",
    "from dataset import NCADataModule, GoalNCADataModule\n",
    "from model import Updater, Perceiver, NCA, GoalNCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5219f164-3418-4b0d-a902-1d5507ce2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_CACHE = Path(\"./seed_goal\")\n",
    "SEED_CACHE_SIZE = 64 # Must be at least the batch_size, to avoid the drop_last, Might not be neccessary tho\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_STEP = 50\n",
    "\n",
    "SEED_CACHE.mkdir(exist_ok=True, parents=True)\n",
    "GRID_SIZE = (40, 40)\n",
    "CELL_FIRE_RATE = 0.5\n",
    "CLIP_VALUE = [-10, 10]\n",
    "ALIVE_THRESHOLD = 0.1\n",
    "USE_ALIVE_CHANNEL = True\n",
    "THUMBNAIL_SIZE = 32 # This controls the size of the target image\n",
    "NUM_HIDDEN_CHANNELS = 20\n",
    "NUM_STATIC_CHANNELS = 1\n",
    "NUM_TARGET_CHANNELS = 3\n",
    "TOTAL_CHANNELS = NUM_HIDDEN_CHANNELS + NUM_STATIC_CHANNELS + NUM_TARGET_CHANNELS + 1\n",
    "OUTPUT_CHANNELS = NUM_HIDDEN_CHANNELS + NUM_TARGET_CHANNELS + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f5f7418-5442-4b1c-9fa8-462675dd1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# from pathlib import Path\n",
    "\n",
    "# pop = Path(\"./pic/32\")\n",
    "# target_image_list = random.choices(list(pop.iterdir()), k=10)\n",
    "\n",
    "target_image_list = ['pic/32/emoji_u1f9d4_1f3fe_200d_2642.png',\n",
    " 'pic/32/emoji_u1f469_1f3fe.png',\n",
    " 'pic/32/emoji_u1f468_200d_1f469_200d_1f467_200d_1f467.png',\n",
    " 'pic/32/emoji_u1f9c8.png',\n",
    " 'pic/32/emoji_u1fab5.png',\n",
    " 'pic/32/emoji_u1f31c.png',\n",
    " 'pic/32/emoji_u1f19a.png',\n",
    " 'pic/32/emoji_u1f508.png',\n",
    " 'pic/32/emoji_u1f469_1f3ff_200d_1f373.png',\n",
    " 'pic/32/emoji_u1f469_200d_1f469_200d_1f466_200d_1f466.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4d00eaca-b84d-4d17-ac7c-29fcf80683eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GOALS = len(target_image_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bb2408b",
   "metadata": {},
   "source": [
    "Similar to `growing_nca`, we will define our grid, target emojis and NCA model architecture. `goal_nca` is different from `growing_nca` in that it is able to form into different target emojis based on the goal signal emitted by the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2aa0e328-ef21-4e97-8f68-76e679a82a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_dm = GoalNCADataModule(\n",
    "    seed_cache_dir=SEED_CACHE, \n",
    "    grid_size=GRID_SIZE, \n",
    "    num_hidden_channels=NUM_HIDDEN_CHANNELS, \n",
    "    num_target_channels=NUM_TARGET_CHANNELS, \n",
    "    num_static_channels=NUM_STATIC_CHANNELS, \n",
    "    target_image_path=target_image_list,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    THUMBNAIL_SIZE = THUMBNAIL_SIZE, # This controls the size of the target image\n",
    "    clear_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d156df",
   "metadata": {},
   "outputs": [],
   "source": [
    "NET_HIDDEN_STATE = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a71d296d-fab0-4234-8a21-3d0d055f0415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceiver(\n",
       "  (model): Conv2d(9, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceiver_net = Perceiver(in_channels=OUTPUT_CHANNELS, out_channels=NET_HIDDEN_STATE, groups=1)\n",
    "perceiver_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "46ad09dc-44be-4eef-a161-ad2d3c92381e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Updater(\n",
       "  (out): Sequential(\n",
       "    (0): Conv2d(10, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updater_net = Updater(in_channels=NET_HIDDEN_STATE, out_channels=OUTPUT_CHANNELS)\n",
    "updater_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "237cf682-28b4-49b6-9571-02ce8e8ac015",
   "metadata": {},
   "outputs": [],
   "source": [
    "nca_2d = GoalNCA(\n",
    "    num_hidden_channels = NUM_HIDDEN_CHANNELS,\n",
    "    num_target_channels = NUM_TARGET_CHANNELS,\n",
    "    num_static_channels = NUM_STATIC_CHANNELS,\n",
    "    use_alive_channel = USE_ALIVE_CHANNEL,\n",
    "    perceiver = perceiver_net,\n",
    "    updater= updater_net,\n",
    "    num_goals=NUM_GOALS,\n",
    "    cell_fire_rate = CELL_FIRE_RATE,\n",
    "    clip_value = CLIP_VALUE,\n",
    "    alive_threshold = ALIVE_THRESHOLD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4d8161be-a172-494b-85ad-5cc7f7c70c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = NCALightningModule(\n",
    "    model = nca_2d,\n",
    "    train_step = TRAIN_STEP,\n",
    "    seed_cache_dir = SEED_CACHE,\n",
    "    seed_cache_size = SEED_CACHE_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ca11e7-3600-46bc-910d-4094ee863b71",
   "metadata": {},
   "source": [
    "Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "61788def-62b5-44f7-a8a5-bfbcec553e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_module.callback import get_num_generator, VisualizeBestSeed, VisualizeRun, GoalCacheBestSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8ac66af6-f799-4d41-9221-5ca8802c7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_func = transform.create_corrupt_2d_circular(h=GRID_SIZE[0], w=GRID_SIZE[1], radius=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8be52-dfcb-4b8d-bbba-a47aa65feaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "num_gen = get_num_generator(SEED_CACHE_SIZE)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1000,\n",
    "    reload_dataloaders_every_n_epochs=1,\n",
    "    callbacks=[\n",
    "        GoalCacheBestSeed(cache_dir=SEED_CACHE, num_generator=num_gen),\n",
    "        VisualizeBestSeed(),\n",
    "        VisualizeRun(interval=3, simulate_step=TRAIN_STEP),\n",
    "        # CacheCorruptedSeed(cache_dir=SEED_CACHE, num_generator=num_gen, loss_threshold=0.15, corrupt_func=corrupt_func)\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainer.fit(lit_model, lit_dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
